"""
Ver2: TabNet Model for Change Prediction
========================================

ëª©ì : TabNetì˜ Sequential Attentionì„ í™œìš©í•œ ë³€í™” ì˜ˆì¸¡
íŠ¹ì§•: 
- í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì„± ì„ íƒ
- Attention ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì¤‘ìš” íŠ¹ì„± ìë™ ì‹ë³„
- Ver1ì˜ TabNetì„ Ver2 (ë³€í™” ì˜ˆì¸¡)ì— ì ìš©
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from pytorch_tabnet.tab_model import TabNetRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
import os
from pathlib import Path

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


class TabNetChangePredictor:
    """TabNet ê¸°ë°˜ ë³€í™” ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, target_variable, device='auto', random_state=42):
        """
        Args:
            target_variable: ì˜ˆì¸¡í•  ê±´ê°•ì§€í‘œ (ì˜ˆ: 'ì²´ì¤‘', 'í˜ˆë‹¹')
            device: 'auto', 'cuda', 'cpu'
            random_state: ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ
        """
        self.target_variable = target_variable
        self.random_state = random_state
        self.model = None
        self.scaler_X = StandardScaler()
        self.feature_names = None
        self.metrics = {}
        
        # Device ì„¤ì •
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        print(f"\n   ğŸ–¥ï¸  ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
    def prepare_data(self, df):
        """ë°ì´í„° ì¤€ë¹„ - ì¶”ê°€ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ """
        print(f"\n{'='*80}")
        print(f"ğŸ“Š [{self.target_variable}] ë°ì´í„° ì¤€ë¹„ (ê°œì„  ë²„ì „)")
        print(f"{'='*80}")
        
        # 1. ì‹ìŠµê´€ ë³€í™” íŠ¹ì„±
        diet_change_cols = [col for col in df.columns 
                           if '_change' in col and 'ê±´ê°•' not in col 
                           and not any(bio in col for bio in ['ì²´ì¤‘', 'ì²´ì§ˆëŸ‰ì§€ìˆ˜', 'í—ˆë¦¬ë‘˜ë ˆ', 'SBP', 'DBP', 'TG'])]
        
        # 2. âœ… ë‹¤ë¥¸ ê±´ê°•ì§€í‘œ baseline ì¶”ê°€ (ë…ë¦½ì  ì§€í‘œë§Œ ì„ íƒ)
        # âš ï¸ ìˆ˜í•™ì /ìƒê´€ì ìœ¼ë¡œ ì—°ê²°ëœ ì§€í‘œëŠ” ì œì™¸í•˜ì—¬ Data Leakage ë°©ì§€
        
        # ê±´ê°•ì§€í‘œ ê·¸ë£¹ ì •ì˜
        obesity_indicators = ['ì²´ì¤‘', 'ì²´ì§ˆëŸ‰ì§€ìˆ˜', 'í—ˆë¦¬ë‘˜ë ˆ(WAIST)']  # ë¹„ë§Œ ê´€ë ¨ (ì„œë¡œ ê°•í•œ ìƒê´€)
        bp_indicators = ['SBP', 'DBP']  # í˜ˆì•• ê´€ë ¨ (ì„œë¡œ ê°•í•œ ìƒê´€)
        metabolic_indicators = ['TG']  # ëŒ€ì‚¬ ê´€ë ¨ (ë…ë¦½ì )
        
        other_health_baselines = []
        
        # íƒ€ê²Ÿì´ ë¹„ë§Œ ì§€í‘œì¸ ê²½ìš° â†’ í˜ˆì••, ëŒ€ì‚¬ ì§€í‘œë§Œ ì‚¬ìš©
        if self.target_variable in obesity_indicators:
            for indicator in bp_indicators + metabolic_indicators:
                baseline_col = f'{indicator}_baseline'
                if baseline_col in df.columns:
                    other_health_baselines.append(baseline_col)
        
        # íƒ€ê²Ÿì´ í˜ˆì•• ì§€í‘œì¸ ê²½ìš° â†’ ë¹„ë§Œ, ëŒ€ì‚¬ ì§€í‘œ ì‚¬ìš© (ë‹¤ë¥¸ í˜ˆì•• ì œì™¸)
        elif self.target_variable in bp_indicators:
            for indicator in obesity_indicators + metabolic_indicators:
                baseline_col = f'{indicator}_baseline'
                if baseline_col in df.columns:
                    other_health_baselines.append(baseline_col)
            # ë‹¤ë¥¸ í˜ˆì•• ì§€í‘œ ì œì™¸
            other_bp = [bp for bp in bp_indicators if bp != self.target_variable]
            for indicator in other_bp:
                baseline_col = f'{indicator}_baseline'
                if baseline_col in other_health_baselines:
                    other_health_baselines.remove(baseline_col)
        
        # íƒ€ê²Ÿì´ ëŒ€ì‚¬ ì§€í‘œì¸ ê²½ìš° â†’ ëª¨ë“  ì§€í‘œ ì‚¬ìš© ê°€ëŠ¥
        elif self.target_variable in metabolic_indicators:
            for indicator in obesity_indicators + bp_indicators:
                baseline_col = f'{indicator}_baseline'
                if baseline_col in df.columns:
                    other_health_baselines.append(baseline_col)
        
        print(f"\n   ğŸ“ˆ ì¶”ê°€ëœ ë‹¤ë¥¸ ê±´ê°•ì§€í‘œ baseline: {len(other_health_baselines)}ê°œ")
        for col in other_health_baselines:
            print(f"      - {col}")
        
        # 3. âœ… íŒŒìƒ íŠ¹ì„± ìƒì„± (df_cleanì— ì¶”ê°€)
        df_temp = df.copy()
        
        # BMI ì¹´í…Œê³ ë¦¬ (baseline ê¸°ì¤€)
        if 'ì²´ì§ˆëŸ‰ì§€ìˆ˜_baseline' in df_temp.columns:
            df_temp['BMI_category'] = pd.cut(
                df_temp['ì²´ì§ˆëŸ‰ì§€ìˆ˜_baseline'], 
                bins=[0, 18.5, 23, 25, 30, 100],
                labels=[0, 1, 2, 3, 4]  # ì €ì²´ì¤‘, ì •ìƒ, ê³¼ì²´ì¤‘, ë¹„ë§Œ1, ë¹„ë§Œ2
            ).astype(float)
        
        # ëŒ€ì‚¬ì¦í›„êµ° ìœ„í—˜ ì ìˆ˜ (baseline ê¸°ì¤€)
        metabolic_risk_score = 0
        if 'ì²´ì§ˆëŸ‰ì§€ìˆ˜_baseline' in df_temp.columns:
            metabolic_risk_score += (df_temp['ì²´ì§ˆëŸ‰ì§€ìˆ˜_baseline'] >= 25).astype(int)
        if 'SBP_baseline' in df_temp.columns:
            metabolic_risk_score += (df_temp['SBP_baseline'] >= 130).astype(int)
        if 'DBP_baseline' in df_temp.columns:
            metabolic_risk_score += (df_temp['DBP_baseline'] >= 85).astype(int)
        if 'TG_baseline' in df_temp.columns:
            metabolic_risk_score += (df_temp['TG_baseline'] >= 150).astype(int)
        
        df_temp['metabolic_risk_score'] = metabolic_risk_score
        
        # ê±´ê°•í•œ ì‹ìŠµê´€ ì ìˆ˜ (ë³´í˜¸ ì‹ìŠµê´€ ì¦ê°€ = ê¸ì •ì )
        healthy_items = ['ì±„ì†Œ_change', 'ê³¼ì¼_change', 'ë‹¨ë°±ì§ˆë¥˜_change', 'ìœ ì œí’ˆ_change', 'ê³¡ë¥˜_change']
        healthy_score = 0
        for item in healthy_items:
            if item in df_temp.columns:
                healthy_score += df_temp[item]
        df_temp['healthy_eating_score'] = healthy_score
        
        # ë¶ˆê±´ê°•í•œ ì‹ìŠµê´€ ì ìˆ˜ (ìœ„í—˜ ì‹ìŠµê´€ ì¦ê°€ = ë¶€ì •ì )
        unhealthy_items = ['ê°„ì‹ë¹ˆë„_change', 'ê³ ì§€ë°© ìœ¡ë¥˜_change', 'ë‹¨ë§›_change', 
                          'ìŒë£Œë¥˜_change', 'ì¸ìŠ¤í„´íŠ¸ ê°€ê³µì‹í’ˆ_change', 'ì§  ê°„_change', 
                          'ì§  ì‹ìŠµê´€_change', 'íŠ€ê¹€_change']
        unhealthy_score = 0
        for item in unhealthy_items:
            if item in df_temp.columns:
                unhealthy_score += df_temp[item]
        df_temp['unhealthy_eating_score'] = unhealthy_score
        
        # ìˆœ ì‹ìŠµê´€ ê°œì„  ì ìˆ˜
        df_temp['net_diet_improvement'] = df_temp['healthy_eating_score'] - df_temp['unhealthy_eating_score']
        
        # 4. ì „ì²´ íŠ¹ì„± ëª©ë¡
        additional_features = ['time_gap_days']
        derived_features = []
        
        # íŒŒìƒ íŠ¹ì„± ì¶”ê°€
        if 'BMI_category' in df_temp.columns:
            derived_features.append('BMI_category')
        if 'metabolic_risk_score' in df_temp.columns:
            derived_features.append('metabolic_risk_score')
        if 'healthy_eating_score' in df_temp.columns:
            derived_features.append('healthy_eating_score')
        if 'unhealthy_eating_score' in df_temp.columns:
            derived_features.append('unhealthy_eating_score')
        if 'net_diet_improvement' in df_temp.columns:
            derived_features.append('net_diet_improvement')
        
        feature_cols = diet_change_cols + other_health_baselines + additional_features + derived_features
        self.feature_names = feature_cols
        
        # íƒ€ê²Ÿ
        target_col = f'{self.target_variable}_change'
        
        # NaN ì œê±°
        valid_idx = df_temp[feature_cols + [target_col]].notna().all(axis=1)
        df_clean = df_temp[valid_idx].copy()
        
        X = df_clean[feature_cols].values
        y = df_clean[target_col].values.reshape(-1, 1)
        
        print(f"\n   âœ… ìœ íš¨ ìƒ˜í”Œ: {len(df_clean):,}ê°œ")
        print(f"   âœ… ì´ íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}ê°œ")
        print(f"      - ì‹ìŠµê´€ ë³€í™”: {len(diet_change_cols)}ê°œ")
        print(f"      - ë‹¤ë¥¸ ê±´ê°•ì§€í‘œ baseline: {len(other_health_baselines)}ê°œ")
        print(f"      - íŒŒìƒ íŠ¹ì„±: {len(derived_features)}ê°œ")
        print(f"      - ê¸°íƒ€: {len(additional_features)}ê°œ")
        print(f"   âœ… íƒ€ê²Ÿ: {target_col}")
        
        # ğŸ” íŠ¹ì„± ëª©ë¡ ìƒì„¸ ì¶œë ¥
        print(f"\n   ğŸ” ì‚¬ìš©ëœ íŠ¹ì„± ìƒì„¸ ëª©ë¡ (ì´ {len(feature_cols)}ê°œ):")
        print("   " + "="*76)
        for i, col in enumerate(feature_cols, 1):
            print(f"      {i:2d}. {col}")
        print("   " + "="*76)
        
        # CSV ì €ì¥
        features_df = pd.DataFrame({
            'Feature_Index': range(1, len(feature_cols)+1),
            'Feature_Name': feature_cols
        })
        features_csv = f'./result/features_used_{self.target_variable}.csv'
        Path(features_csv).parent.mkdir(parents=True, exist_ok=True)
        features_df.to_csv(features_csv, index=False, encoding='utf-8-sig')
        print(f"   ğŸ’¾ íŠ¹ì„± ëª©ë¡ ì €ì¥: {features_csv}")
        
        # âš ï¸ Leakage ê²€ì¦
        target_baseline = f'{self.target_variable}_baseline'
        if target_baseline in feature_cols:
            print(f"\n   ğŸš¨ ERROR: íƒ€ê²Ÿì˜ baseline ë°œê²¬! Data Leakage!")
            print(f"      - {target_baseline}")
            raise ValueError(f"Data Leakage detected: {target_baseline} in features")
        else:
            print(f"\n   âœ… íƒ€ê²Ÿ baseline ì—†ìŒ: {target_baseline} ì œì™¸ë¨")
        
        return X, y, df_clean
    
    def train(self, X, y, test_size=0.2, val_size=0.1, 
              max_epochs=200, patience=20, batch_size=256):
        """TabNet ëª¨ë¸ í•™ìŠµ"""
        print(f"\n{'='*80}")
        print(f"ğŸ¯ [{self.target_variable}] TabNet í•™ìŠµ")
        print(f"{'='*80}")
        
        # Train / Validation / Test ë¶„í• 
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        
        val_ratio = val_size / (1 - test_size)
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_ratio, random_state=self.random_state
        )
        
        print(f"   ğŸ“Š Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}")
        
        # TabNet ëª¨ë¸ ìƒì„±
        self.model = TabNetRegressor(
            n_d=16,                    # Dimension of prediction layer
            n_a=16,                    # Dimension of attention layer
            n_steps=5,                 # Number of sequential decision steps
            gamma=1.5,                 # Relaxation parameter
            n_independent=2,           # Number of independent GLU layers
            n_shared=2,                # Number of shared GLU layers
            lambda_sparse=1e-4,        # Sparsity regularization
            optimizer_fn=torch.optim.Adam,
            optimizer_params=dict(lr=2e-2),
            scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,
            scheduler_params=dict(mode='min', patience=5, factor=0.5),
            mask_type='entmax',        # "sparsemax" or "entmax"
            seed=self.random_state,
            device_name=self.device,
            verbose=0
        )
        
        # í•™ìŠµ
        print(f"\n   ğŸ”„ TabNet í•™ìŠµ ì¤‘ (ìµœëŒ€ {max_epochs} epochs)...")
        
        self.model.fit(
            X_train=X_train, y_train=y_train,
            eval_set=[(X_val, y_val)],
            eval_name=['val'],
            eval_metric=['rmse'],
            max_epochs=max_epochs,
            patience=patience,
            batch_size=batch_size,
            virtual_batch_size=128,
            num_workers=0,
            drop_last=False
        )
        
        # í•™ìŠµ ê³¡ì„  ì €ì¥
        self._plot_learning_curves()
        
        # í‰ê°€
        self._evaluate(X_train, y_train, X_val, y_val, X_test, y_test)
        
        return X_test, y_test
    
    def _evaluate(self, X_train, y_train, X_val, y_val, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        print(f"\n   ğŸ“ˆ ì„±ëŠ¥ í‰ê°€:")
        
        datasets = {
            'Train': (X_train, y_train),
            'Val': (X_val, y_val),
            'Test': (X_test, y_test)
        }
        
        for name, (X, y) in datasets.items():
            y_pred = self.model.predict(X)
            
            r2 = r2_score(y, y_pred)
            rmse = np.sqrt(mean_squared_error(y, y_pred))
            mae = mean_absolute_error(y, y_pred)
            
            # ë°©í–¥ ì •í™•ë„
            direction_acc = np.mean(np.sign(y) == np.sign(y_pred)) * 100
            
            self.metrics[name] = {
                'RÂ²': r2,
                'RMSE': rmse,
                'MAE': mae,
                'Direction_Accuracy': direction_acc
            }
            
            print(f"\n      [{name}]")
            print(f"         RÂ² = {r2:.4f}")
            print(f"         RMSE = {rmse:.4f}")
            print(f"         MAE = {mae:.4f}")
            print(f"         ë°©í–¥ ì •í™•ë„ = {direction_acc:.1f}%")
    
    def _plot_learning_curves(self):
        """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        if not hasattr(self.model, 'history'):
            return
        
        history = self.model.history
        
        plt.figure(figsize=(12, 5))
        
        # Loss curve
        plt.subplot(1, 2, 1)
        try:
            # Try accessing history as dict or object
            loss_data = None
            val_data = None
            
            if hasattr(history, 'history'):
                loss_data = history.history.get('loss', None)
                val_data = history.history.get('val_0_rmse', None)
            else:
                try:
                    loss_data = history.get('loss', None) if hasattr(history, 'get') else None
                    val_data = history.get('val_0_rmse', None) if hasattr(history, 'get') else None
                except:
                    pass
            
            if loss_data is not None:
                plt.plot(loss_data, label='Train Loss', linewidth=2)
            if val_data is not None:
                plt.plot(val_data, label='Val RMSE', linewidth=2)
                
        except Exception as e:
            print(f"   âš ï¸  í•™ìŠµ ê³¡ì„  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Loss', fontsize=12)
        plt.title(f'{self.target_variable} TabNet í•™ìŠµ ê³¡ì„ ', fontsize=14)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # Learning rate
        plt.subplot(1, 2, 2)
        try:
            lr_data = None
            if hasattr(history, 'history'):
                lr_data = history.history.get('lr', None)
            else:
                try:
                    lr_data = history.get('lr', None) if hasattr(history, 'get') else None
                except:
                    pass
                    
            if lr_data is not None:
                plt.plot(lr_data, linewidth=2, color='orange')
                plt.xlabel('Epoch', fontsize=12)
                plt.ylabel('Learning Rate', fontsize=12)
                plt.title('Learning Rate Schedule', fontsize=14)
                plt.grid(True, alpha=0.3)
        except Exception:
            pass
        
        plt.tight_layout()
        output_path = f'./result/tabnet_{self.target_variable}_learning_curve.png'
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"\n   ğŸ’¾ í•™ìŠµ ê³¡ì„  ì €ì¥: {output_path}")
        plt.close()
    
    def plot_feature_importance(self, top_n=20):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        # TabNetì˜ feature importance
        importance = self.model.feature_importances_
        indices = np.argsort(importance)[::-1][:top_n]
        
        plt.figure(figsize=(12, 8))
        
        # Bar plot
        plt.subplot(1, 2, 1)
        plt.barh(range(top_n), importance[indices])
        plt.yticks(range(top_n), [self.feature_names[i] for i in indices])
        plt.xlabel('Feature Importance', fontsize=12)
        plt.title(f'{self.target_variable} TabNet íŠ¹ì„± ì¤‘ìš”ë„ (Top {top_n})', fontsize=14)
        plt.grid(True, alpha=0.3, axis='x')
        
        # Pie chart (top 10)
        plt.subplot(1, 2, 2)
        top_10_indices = indices[:10]
        top_10_importance = importance[top_10_indices]
        top_10_names = [self.feature_names[i][:15] for i in top_10_indices]  # ì´ë¦„ ì§§ê²Œ
        
        plt.pie(top_10_importance, labels=top_10_names, autopct='%1.1f%%', startangle=90)
        plt.title('Top 10 íŠ¹ì„± ë¹„ìœ¨', fontsize=14)
        
        plt.tight_layout()
        output_path = f'./result/tabnet_{self.target_variable}_feature_importance.png'
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"   ğŸ’¾ íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥: {output_path}")
        plt.close()
    
    def plot_predictions(self, X_test, y_test):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        y_pred = self.model.predict(X_test)
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # 1. Scatter plot
        axes[0].scatter(y_test, y_pred, alpha=0.5, s=20)
        axes[0].plot([y_test.min(), y_test.max()], 
                     [y_test.min(), y_test.max()], 
                     'r--', lw=2, label='Perfect Prediction')
        axes[0].set_xlabel(f'ì‹¤ì œ {self.target_variable} ë³€í™”', fontsize=12)
        axes[0].set_ylabel(f'ì˜ˆì¸¡ {self.target_variable} ë³€í™”', fontsize=12)
        axes[0].set_title(f'TabNet ì˜ˆì¸¡ vs ì‹¤ì œ (Test RÂ² = {self.metrics["Test"]["RÂ²"]:.4f})', fontsize=14)
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. Residuals plot
        residuals = y_test.flatten() - y_pred.flatten()
        axes[1].scatter(y_pred, residuals, alpha=0.5, s=20)
        axes[1].axhline(y=0, color='r', linestyle='--', lw=2)
        axes[1].set_xlabel(f'ì˜ˆì¸¡ {self.target_variable} ë³€í™”', fontsize=12)
        axes[1].set_ylabel('ì”ì°¨', fontsize=12)
        axes[1].set_title('ì”ì°¨ ë¶„í¬', fontsize=14)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        output_path = f'./result/tabnet_{self.target_variable}_predictions.png'
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"   ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {output_path}")
        plt.close()
    
    def plot_attention_masks(self, X_sample, sample_idx=0):
        """Attention mask ì‹œê°í™” (TabNetì˜ í•µì‹¬ íŠ¹ì§•)"""
        try:
            # Explain í•¨ìˆ˜ë¡œ attention mask ì¶”ì¶œ
            explain_matrix, masks = self.model.explain(X_sample[:10])  # ìƒ˜í”Œ 10ê°œë§Œ
            
            # masksê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(masks, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ masks ë°ì´í„° ì¶”ì¶œ
                if 'masks' in masks:
                    masks = masks['masks']
                else:
                    # ë”•ì…”ë„ˆë¦¬ì˜ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                    masks = list(masks.values())[0]
            
            # numpy arrayë¡œ ë³€í™˜
            if not isinstance(masks, np.ndarray):
                masks = np.array(masks)
            
            fig, axes = plt.subplots(2, 5, figsize=(20, 8))
            axes = axes.flatten()
            
            # masks shape: (n_samples, n_features) ë˜ëŠ” (n_steps, n_samples, n_features)
            # í‰ê·  attention ì‚¬ìš©
            if len(masks.shape) == 3:
                # (n_steps, n_samples, n_features) -> (n_samples, n_features)
                avg_masks = masks.mean(axis=0)
            else:
                avg_masks = masks
            
            for i in range(min(10, avg_masks.shape[0])):
                mask = avg_masks[i]
                
                # Maskë¥¼ íŠ¹ì„±ë³„ë¡œ ì‹œê°í™”
                axes[i].barh(range(len(self.feature_names)), mask, height=0.8)
                axes[i].set_yticks(range(len(self.feature_names)))
                axes[i].set_yticklabels([name[:20] for name in self.feature_names], fontsize=8)
                axes[i].set_xlabel('Attention', fontsize=10)
                axes[i].set_title(f'Sample {i+1}', fontsize=12)
                axes[i].grid(True, alpha=0.3, axis='x')
            
            plt.suptitle(f'{self.target_variable} TabNet Attention Masks', fontsize=16)
            plt.tight_layout()
            
            output_path = f'./result/tabnet_{self.target_variable}_attention_masks.png'
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            print(f"   ğŸ’¾ Attention masks ì €ì¥: {output_path}")
            plt.close()
            
        except Exception as e:
            print(f"   âš ï¸  Attention masks ì‹œê°í™” ê±´ë„ˆëœ€: {str(e)}")
            plt.close('all')
    
    def save_model(self, output_dir='./result/models'):
        """ëª¨ë¸ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        model_path = os.path.join(output_dir, f'tabnet_{self.target_variable}.zip')
        self.model.save_model(model_path)
        
        print(f"\n   ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}")
    
    def load_model(self, model_dir='./result/models'):
        """ëª¨ë¸ ë¡œë“œ"""
        model_path = os.path.join(model_dir, f'tabnet_{self.target_variable}.zip')
        
        self.model = TabNetRegressor()
        self.model.load_model(model_path)
        
        print(f"   âœ… ëª¨ë¸ ë¡œë“œ: {model_path}")


def train_all_targets(data_path='../data/ver2_paired_visits.csv'):
    """
    ëª¨ë“  ê±´ê°•ì§€í‘œì— ëŒ€í•´ TabNet í•™ìŠµ
    
    Args:
        data_path: Ver2 paired visits ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸: ver2/data/ver2_paired_visits.csv)
    """
    """ëª¨ë“  ê±´ê°•ì§€í‘œì— ëŒ€í•´ TabNet í•™ìŠµ"""
    print("\n" + "="*80)
    print("ğŸš€ Ver2 TabNet ì „ì²´ í•™ìŠµ ì‹œì‘")
    print("="*80)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(data_path)
    print(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ìƒ˜í”Œ")
    
    # ê±´ê°•ì§€í‘œ ëª©ë¡ (ë°ì´í„°ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª… ì‚¬ìš©)
    health_indicators = [
        'ì²´ì¤‘', 'ì²´ì§ˆëŸ‰ì§€ìˆ˜', 'í—ˆë¦¬ë‘˜ë ˆ(WAIST)', 'SBP', 'DBP', 'TG'
    ]
    
    results = {}
    
    for indicator in health_indicators:
        try:
            print(f"\n{'='*80}")
            print(f"ğŸ¯ [{indicator}] TabNet í•™ìŠµ ì‹œì‘")
            print(f"{'='*80}")
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = TabNetChangePredictor(indicator)
            X, y, df_clean = model.prepare_data(df)
            X_test, y_test = model.train(X, y, max_epochs=200, patience=20)
            
            # ì‹œê°í™”
            model.plot_feature_importance()
            model.plot_predictions(X_test, y_test)
            
            # Attention masks (ìƒ˜í”Œ)
            if len(X_test) >= 10:
                model.plot_attention_masks(X_test)
            
            # ëª¨ë¸ ì €ì¥
            model.save_model()
            
            # ê²°ê³¼ ì €ì¥
            results[indicator] = model.metrics['Test']
            
            print(f"\nâœ… [{indicator}] ì™„ë£Œ!")
            
        except Exception as e:
            print(f"\nâŒ [{indicator}] ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            results[indicator] = None
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š TabNet ì „ì²´ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    # None ê°’ ì œê±° (ì‹¤íŒ¨í•œ ì§€í‘œ ì œì™¸)
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if len(valid_results) > 0:
        results_df = pd.DataFrame(valid_results).T
        print("\n", results_df.round(4))
        
        # ê²°ê³¼ ì €ì¥
        output_csv = './result/tabnet_all_results.csv'
        Path(output_csv).parent.mkdir(parents=True, exist_ok=True)
        results_df.to_csv(output_csv)
        print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: {output_csv}")
    else:
        print("\nâš ï¸ ëª¨ë“  ì§€í‘œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        results_df = pd.DataFrame()
    
    return results_df


if __name__ == '__main__':
    # Ver2 ë°ì´í„°ë¡œ ì „ì²´ í•™ìŠµ
    results = train_all_targets()
