"""
Subgroup-Specific Modeling - ì„¸ë¶€ ê·¸ë£¹ë³„ ëª¨ë¸ í•™ìŠµ
===================================================

ê° ì„¸ë¶€ ê·¸ë£¹(ë‚˜ì´/ì„±ë³„/BMI)ë³„ë¡œ ì „ìš© ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬
ë” ë†’ì€ ì •í™•ë„ì™€ ê°œì¸ë§ì¶¤í˜• ì˜ˆì¸¡ ì œê³µ

Author: Research Team
Date: 2025-11-06
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from pathlib import Path
import joblib
import warnings
warnings.filterwarnings('ignore')

OUTPUT_DIR = Path('./advanced_results/subgroup_models')
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


class SubgroupModeling:
    """ì„¸ë¶€ ê·¸ë£¹ë³„ ì „ìš© ëª¨ë¸"""
    
    def __init__(self, data_path='./advanced_results/data_with_subgroups.csv'):
        """
        Args:
            data_path: ê·¸ë£¹ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„° ê²½ë¡œ
        """
        print("\n" + "="*80)
        print("ğŸ¯ Subgroup-Specific Modeling ì´ˆê¸°í™”")
        print("="*80)
        
        self.df = pd.read_csv(data_path)
        print(f"\nâœ… ë°ì´í„° ë¡œë“œ: {len(self.df):,}ê°œ ìƒ˜í”Œ")
        
        self.health_indicators = [
            'ì²´ì¤‘', 'ì²´ì§ˆëŸ‰ì§€ìˆ˜', 'í—ˆë¦¬ë‘˜ë ˆ(WAIST)', 'SBP', 'DBP', 'TG'
        ]
        
        # ì‹ìŠµê´€ íŠ¹ì„± (19ê°œ)
        self.diet_features = [
            'ê°„ì‹ë¹ˆë„', 'ê³ ì§€ë°© ìœ¡ë¥˜', 'ë‹¨ë§›', 'ë‹¨ë°±ì§ˆë¥˜', 'ê³¡ë¥˜',
            'ê³¼ì¼', 'ìœ ì œí’ˆ', 'ìŒë£Œë¥˜', 'ì¸ìŠ¤í„´íŠ¸ ê°€ê³µì‹í’ˆ',
            'ì§  ê°„', 'ì§  ì‹ìŠµê´€', 'ì±„ì†Œ', 'íŠ€ê¹€',
            'ì‹ì‚¬ ë¹ˆë„', 'ì‹ì‚¬ëŸ‰', 'ì™¸ì‹ë¹ˆë„',
            'ë‚˜ì´', 'ì„±ë³„'  # ì¶”ê°€ ì •ë³´
        ]
        
        # ì„±ë³„ì„ ìˆ«ìë¡œ ì¸ì½”ë”©
        self.df['ì„±ë³„_encoded'] = self.df['ì„±ë³„'].map({'M': 1, 'F': 0})
        
        print(f"âœ… ê±´ê°•ì§€í‘œ: {len(self.health_indicators)}ê°œ")
        print(f"âœ… ì‹ìŠµê´€ íŠ¹ì„±: {len(self.diet_features)}ê°œ")
        
    def get_available_features(self):
        """ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” íŠ¹ì„± í™•ì¸"""
        available = []
        for feat in self.diet_features:
            if feat == 'ì„±ë³„':
                # ì„±ë³„ì€ ì¸ì½”ë”©ëœ ë²„ì „ ì‚¬ìš©
                if 'ì„±ë³„_encoded' in self.df.columns:
                    available.append('ì„±ë³„_encoded')
            elif feat in self.df.columns:
                available.append(feat)
        
        print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available)}ê°œ")
        return available
    
    def train_subgroup_model(self, df_subset, target, group_name):
        """
        íŠ¹ì • ê·¸ë£¹ì˜ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
        
        Args:
            df_subset: í•´ë‹¹ ê·¸ë£¹ ë°ì´í„°
            target: ì˜ˆì¸¡ íƒ€ê²Ÿ (ê±´ê°•ì§€í‘œ)
            group_name: ê·¸ë£¹ ì´ë¦„
        
        Returns:
            dict: ëª¨ë¸ ë° ì„±ëŠ¥ ì •ë³´
        """
        # íŠ¹ì„± ì¤€ë¹„
        available_features = self.get_available_features()
        X = df_subset[available_features].fillna(df_subset[available_features].median())
        y = df_subset[target].values
        
        # Train/Test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ëª¨ë¸ í•™ìŠµ (RandomForest + GradientBoosting ì•™ìƒë¸”)
        rf = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        
        gb = GradientBoostingRegressor(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        )
        
        rf.fit(X_train_scaled, y_train)
        gb.fit(X_train_scaled, y_train)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        y_pred_train = (rf.predict(X_train_scaled) + gb.predict(X_train_scaled)) / 2
        y_pred_test = (rf.predict(X_test_scaled) + gb.predict(X_test_scaled)) / 2
        
        # ì„±ëŠ¥ í‰ê°€
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        # Cross-validation
        cv_scores = cross_val_score(
            rf, X_train_scaled, y_train, 
            cv=5, scoring='r2', n_jobs=-1
        )
        
        # Feature importance (RandomForest ê¸°ì¤€)
        importance = pd.DataFrame({
            'feature': available_features,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        result = {
            'group': group_name,
            'target': target,
            'n_samples': len(df_subset),
            'n_train': len(X_train),
            'n_test': len(X_test),
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_mae': train_mae,
            'test_mae': test_mae,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'models': {'rf': rf, 'gb': gb},
            'scaler': scaler,
            'feature_importance': importance,
            'features': available_features
        }
        
        return result
    
    def train_all_subgroups(self):
        """ëª¨ë“  ì„¸ë¶€ ê·¸ë£¹ì— ëŒ€í•´ ëª¨ë¸ í•™ìŠµ"""
        print("\n" + "="*80)
        print("ğŸš€ ì„¸ë¶€ ê·¸ë£¹ë³„ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("="*80)
        
        all_results = []
        
        # 1. ë‚˜ì´ ê·¸ë£¹ë³„
        print("\n[1. ë‚˜ì´ ê·¸ë£¹ë³„ ëª¨ë¸]")
        for age_group in self.df['ë‚˜ì´ê·¸ë£¹'].dropna().unique():
            df_age = self.df[self.df['ë‚˜ì´ê·¸ë£¹'] == age_group]
            
            for target in self.health_indicators:
                if target in df_age.columns:
                    print(f"\n   í•™ìŠµ ì¤‘: {age_group} - {target}")
                    result = self.train_subgroup_model(
                        df_age, target, f"ë‚˜ì´_{age_group}"
                    )
                    all_results.append(result)
                    
                    print(f"      ìƒ˜í”Œ: {result['n_samples']:,}ê°œ")
                    print(f"      Test RÂ²: {result['test_r2']:.4f}")
                    print(f"      Test RMSE: {result['test_rmse']:.4f}")
        
        # 2. ì„±ë³„ ê·¸ë£¹ë³„
        print("\n[2. ì„±ë³„ ê·¸ë£¹ë³„ ëª¨ë¸]")
        for sex in self.df['ì„±ë³„'].dropna().unique():
            df_sex = self.df[self.df['ì„±ë³„'] == sex]
            
            for target in self.health_indicators:
                if target in df_sex.columns:
                    print(f"\n   í•™ìŠµ ì¤‘: {sex} - {target}")
                    result = self.train_subgroup_model(
                        df_sex, target, f"ì„±ë³„_{sex}"
                    )
                    all_results.append(result)
                    
                    print(f"      ìƒ˜í”Œ: {result['n_samples']:,}ê°œ")
                    print(f"      Test RÂ²: {result['test_r2']:.4f}")
                    print(f"      Test RMSE: {result['test_rmse']:.4f}")
        
        # 3. BMI ê·¸ë£¹ë³„
        print("\n[3. BMI ê·¸ë£¹ë³„ ëª¨ë¸]")
        for bmi_group in self.df['BMIê·¸ë£¹'].dropna().unique():
            df_bmi = self.df[self.df['BMIê·¸ë£¹'] == bmi_group]
            
            for target in self.health_indicators:
                if target in df_bmi.columns and target != 'ì²´ì§ˆëŸ‰ì§€ìˆ˜':
                    print(f"\n   í•™ìŠµ ì¤‘: {bmi_group} - {target}")
                    result = self.train_subgroup_model(
                        df_bmi, target, f"BMI_{bmi_group}"
                    )
                    all_results.append(result)
                    
                    print(f"      ìƒ˜í”Œ: {result['n_samples']:,}ê°œ")
                    print(f"      Test RÂ²: {result['test_r2']:.4f}")
                    print(f"      Test RMSE: {result['test_rmse']:.4f}")
        
        self.all_results = all_results
        
        return all_results
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        print("\n" + "="*80)
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
        print("="*80)
        
        # 1. ì„±ëŠ¥ ìš”ì•½ CSV
        summary_data = []
        for result in self.all_results:
            summary_data.append({
                'ê·¸ë£¹': result['group'],
                'ì§€í‘œ': result['target'],
                'ìƒ˜í”Œìˆ˜': result['n_samples'],
                'Train_RÂ²': result['train_r2'],
                'Test_RÂ²': result['test_r2'],
                'CV_RÂ²_mean': result['cv_mean'],
                'CV_RÂ²_std': result['cv_std'],
                'Test_RMSE': result['test_rmse'],
                'Test_MAE': result['test_mae']
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_path = OUTPUT_DIR / 'subgroup_model_performance.csv'
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ì„±ëŠ¥ ìš”ì•½ ì €ì¥: {summary_path}")
        
        # 2. ê° ëª¨ë¸ ì €ì¥
        for idx, result in enumerate(self.all_results):
            model_dir = OUTPUT_DIR / f"{result['group']}_{result['target']}"
            model_dir.mkdir(exist_ok=True)
            
            # ëª¨ë¸ íŒŒì¼
            joblib.dump(result['models'], model_dir / 'models.pkl')
            joblib.dump(result['scaler'], model_dir / 'scaler.pkl')
            
            # Feature importance
            result['feature_importance'].to_csv(
                model_dir / 'feature_importance.csv',
                index=False,
                encoding='utf-8-sig'
            )
        
        print(f"âœ… ëª¨ë¸ íŒŒì¼ ì €ì¥: {len(self.all_results)}ê°œ")
        
        # 3. Top performers
        summary_df_sorted = summary_df.sort_values('Test_RÂ²', ascending=False)
        print("\n[Top 10 ëª¨ë¸ ì„±ëŠ¥]")
        print(summary_df_sorted.head(10)[['ê·¸ë£¹', 'ì§€í‘œ', 'Test_RÂ²', 'Test_RMSE']].to_string(index=False))
        
        return summary_df
    
    def compare_with_overall(self, overall_r2_dict):
        """
        ì„¸ë¶€ ê·¸ë£¹ ëª¨ë¸ vs ì „ì²´ ëª¨ë¸ ë¹„êµ
        
        Args:
            overall_r2_dict: ì „ì²´ ëª¨ë¸ì˜ RÂ² ë”•ì…”ë„ˆë¦¬
                            ì˜ˆ: {'ì²´ì¤‘': 0.9986, 'ì²´ì§ˆëŸ‰ì§€ìˆ˜': 0.9988, ...}
        """
        print("\n" + "="*80)
        print("ğŸ“Š ì„¸ë¶€ ê·¸ë£¹ ëª¨ë¸ vs ì „ì²´ ëª¨ë¸ ë¹„êµ")
        print("="*80)
        
        comparison_data = []
        
        for target in self.health_indicators:
            overall_r2 = overall_r2_dict.get(target, np.nan)
            
            # í•´ë‹¹ ì§€í‘œì˜ ëª¨ë“  ì„¸ë¶€ ê·¸ë£¹ ëª¨ë¸ RÂ²
            subgroup_r2_list = [
                r['test_r2'] for r in self.all_results 
                if r['target'] == target
            ]
            
            if len(subgroup_r2_list) > 0:
                mean_r2 = np.mean(subgroup_r2_list)
                max_r2 = np.max(subgroup_r2_list)
                min_r2 = np.min(subgroup_r2_list)
                
                comparison_data.append({
                    'ì§€í‘œ': target,
                    'ì „ì²´ëª¨ë¸_RÂ²': overall_r2,
                    'ì„¸ë¶€ê·¸ë£¹_í‰ê· _RÂ²': mean_r2,
                    'ì„¸ë¶€ê·¸ë£¹_ìµœëŒ€_RÂ²': max_r2,
                    'ì„¸ë¶€ê·¸ë£¹_ìµœì†Œ_RÂ²': min_r2,
                    'í‰ê· _ê°œì„ ë„': mean_r2 - overall_r2,
                    'ìµœëŒ€_ê°œì„ ë„': max_r2 - overall_r2
                })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # ì €ì¥
        output_path = OUTPUT_DIR / 'comparison_overall_vs_subgroup.csv'
        comparison_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ë¹„êµ ê²°ê³¼ ì €ì¥: {output_path}")
        
        # ì¶œë ¥
        print("\n", comparison_df.to_string(index=False))
        
        return comparison_df


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸš€ Subgroup-Specific Modeling ì‹œì‘")
    print("="*80)
    
    # Initialize
    modeler = SubgroupModeling()
    
    # Train all subgroups
    results = modeler.train_all_subgroups()
    
    # Save results
    summary_df = modeler.save_results()
    
    # Compare with overall model (Ver1 ê²°ê³¼)
    # ì‹¤ì œ Ver1 RÂ² ê°’ (README ì°¸ê³ )
    overall_r2 = {
        'ì²´ì§ˆëŸ‰ì§€ìˆ˜': 0.9988,
        'ì²´ì¤‘': 0.9986,
        'í—ˆë¦¬ë‘˜ë ˆ(WAIST)': 0.9651,
        'DBP': 0.8164,
        'TG': 0.8093,
        'SBP': 0.8068
    }
    
    comparison_df = modeler.compare_with_overall(overall_r2)
    
    print("\n" + "="*80)
    print("âœ… Phase 2 ì™„ë£Œ: ì„¸ë¶€ ê·¸ë£¹ë³„ ëª¨ë¸ í•™ìŠµ")
    print("="*80)
    print(f"\nê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR.absolute()}")
    print(f"ì´ {len(results)}ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")


if __name__ == '__main__':
    main()
