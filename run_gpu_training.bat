@echo off
echo ==================================
echo ğŸš€ GPU ê°€ì† í•™ìŠµ
echo ==================================
echo ì‹œì‘ ì‹œê°„: %date% %time%
echo.

:: CUDA í™•ì¸
echo ğŸ” GPU í™•ì¸ ì¤‘...
python -c "import torch; print('GPU ì‚¬ìš© ê°€ëŠ¥!' if torch.cuda.is_available() else 'GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰'); print(f'GPU: {torch.cuda.get_device_name(0)}' if torch.cuda.is_available() else '')"

if errorlevel 1 (
    echo.
    echo âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
    echo ğŸ’¡ install_gpu.batë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.
    pause
    exit /b 1
)

echo.
echo ì„¤ì •:
echo   - ë°”ì´ì˜¤ë§ˆì»¤: 6ê°œ
echo   - ëª¨ë¸: TabNet + Stacking Ensemble
echo   - ê°€ì†: GPU (CUDA)
echo   - Optuna ìµœì í™”: ë¹„í™œì„±í™” (ì•ˆì •ì„±)
echo   - ì˜ˆìƒ ì‹œê°„: 30ë¶„~1ì‹œê°„ (GPU ê°€ì†)
echo.

cd src

python -c "import torch; import os; os.environ['CUDA_VISIBLE_DEVICES'] = '0' if torch.cuda.is_available() else ''; from TABNET_ENHANCED_MODEL import main; import time; start = time.time(); print('='*80); print('ğŸ§  GPU ê°€ì† TabNet + Stacking í•™ìŠµ ì‹œì‘'); print('='*80); print(); results, summary = main(use_tabnet_stacking=True, use_optuna=False, optuna_trials=1); elapsed = time.time() - start; hours = int(elapsed // 3600); minutes = int((elapsed %% 3600) // 60); print(); print('='*80); print('âœ… í•™ìŠµ ì™„ë£Œ!'); print('='*80); print(f'ì´ ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„'); print(); print('ğŸ“Š ìµœì¢… ê²°ê³¼:'); print(summary.to_string(index=False))"

echo.
echo ==================================
echo âœ… ì™„ë£Œ
echo ==================================
echo ì¢…ë£Œ ì‹œê°„: %date% %time%
pause
